{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks With Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning networks tend to be massive with dozens or hundreds of layers, that's where the term \"deep\" comes from. You can build one of these deep networks using only weight matrices as we did in the previous notebook, but in general it's very cumbersome and difficult to implement. PyTorch has a nice module nn that provides a nice way to efficiently build large neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "%matplotlib inline\n",
    "%config inlinebackend.figure_formate = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into trainloader and we make that an iterator with iter(trainloader). Later, we'll use this to loop through the dataset for training.\n",
    "\n",
    "You'll notice I created the trainloader with a batch size of 64, and shuffle=True. The batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a batch. And shuffle=True tells it to shuffle the dataset every time we start going through the data loader again. But here I'm just grabbing the first batch so we can check out the data. We can see below that images is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what one of the images looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');   # squeeze() remove single dimensional entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Flatten the batch of images images. Then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer. Leave the output layer without an activation, we'll add one that gives us a probability distribution next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Flatten the input images\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "\n",
    "# create parameers\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn((10))\n",
    "\n",
    "# calculate the output \n",
    "h = activation(torch.mm(inputs, w1) + b1)\n",
    "out = torch.mm(h, w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
